{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556e605a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11d0cfe50>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from functorch import vmap\n",
    "from ResNet import ResNet\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import glob\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_built() \\\n",
    "    else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(device)\n",
    "\n",
    "torch.manual_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b53b01c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ResNet(num_classes=100,n=9).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c062994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define standard data transforms for CIFAR100\n",
    "# CIFAR100 mean and std:\n",
    "# mean = [0.5071, 0.4867, 0.4408], std = [0.2675, 0.2565, 0.2761]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5071, 0.4867, 0.4408],\n",
    "        std=[0.2675, 0.2565, 0.2761]\n",
    "    ),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5071, 0.4867, 0.4408],\n",
    "        std=[0.2675, 0.2565, 0.2761]\n",
    "    ),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "221a7d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_dataset=torchvision.datasets.CIFAR100(root='./data',train=True,download=True,transform=train_transform)\n",
    "test_dataset=torchvision.datasets.CIFAR100(root='./data',train=False,download=True,transform=test_transform)\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e87b2acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir='checkpoints'\n",
    "checkpoint_epoch = 30\n",
    "checkpoint_path = os.path.join(checkpoint_dir, f'resnet_epoch_{checkpoint_epoch}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b5b09ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one training example (x, y)\n",
    "# Get a batch from the train_loader and pick the first example\n",
    "x_batch, y_batch = next(iter(train_loader))\n",
    "x = x_batch[0]\n",
    "y = y_batch[0].item()\n",
    "\n",
    "# move to device\n",
    "x = x.unsqueeze(0).to(device)  # add batch dimension\n",
    "y = torch.tensor([y], device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f89a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6500])\n",
      "Self-influence for this example at checkpoint: 52.753872\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- assume you already have these ---\n",
    "# model: trained ResNet (e.g., ResNet-56 or ResNet-50)\n",
    "# checkpoint_path: path to a saved checkpoint (e.g. \"ckpt_epoch_60.pt\")\n",
    "# x, y: a single training example (tensor and its label)\n",
    "\n",
    "# load weights from a checkpoint\n",
    "model.load_state_dict(torch.load(checkpoint_path)['model_state_dict'])\n",
    "model.eval()  # important: use evaluation mode\n",
    "\n",
    "\n",
    "# we want gradients w.r.t. last layer only\n",
    "params = list(model.parameters())[-2:]  # usually weight, bias\n",
    "\n",
    "# compute loss with gradient tracking enabled\n",
    "with torch.set_grad_enabled(True):\n",
    "    outputs = model(x)\n",
    "    loss = F.cross_entropy(outputs, y, reduction='sum')\n",
    "\n",
    "# gradient of loss w.r.t. last-layer parameters\n",
    "grads = torch.autograd.grad(loss, params, create_graph=False, retain_graph=False)\n",
    "\n",
    "# flatten and concatenate all gradients\n",
    "flat_grads = torch.cat([g.reshape(-1) for g in grads if g is not None])\n",
    "\n",
    "# compute squared L2 norm â€” the self-influence at this checkpoint\n",
    "self_influence = (flat_grads ** 2).sum().item()\n",
    "\n",
    "print(f\"Self-influence for this example at checkpoint: {self_influence:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a71a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfInfluence:\n",
    "    \"\"\"\n",
    "    Computes TracInCP self-influence scores across multiple checkpoints.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, device='cpu', last_layer_only=True):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.last_layer_only = last_layer_only\n",
    "\n",
    "        # identify the target parameters (usually last layer)\n",
    "        params = list(model.parameters())\n",
    "        self.target_params = params[-2:] if last_layer_only else params\n",
    "\n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"Load model weights from a saved checkpoint.\"\"\"\n",
    "        state_dict = torch.load(checkpoint_path, map_location=self.device)['model_state_dict']\n",
    "        self.model.load_state_dict(state_dict)\n",
    "        self.model.eval()\n",
    "\n",
    "    def _per_sample_grad(self, x, y):\n",
    "        \"\"\"Compute flattened gradient vector for a single sample.\"\"\"\n",
    "        out = self.model(x.unsqueeze(0))\n",
    "        loss = F.cross_entropy(out, y.unsqueeze(0), reduction='sum')\n",
    "        grads = torch.autograd.grad(loss, self.target_params,\n",
    "                                    retain_graph=False, create_graph=False)\n",
    "        flat = torch.cat([g.reshape(-1) for g in grads if g is not None])\n",
    "        return flat\n",
    "\n",
    "    def compute_batch_influence(self, inputs, labels):\n",
    "        \"\"\"\n",
    "        Compute self-influence for each example in a batch.\n",
    "        Returns: tensor of shape [B] with self-influence scores.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "\n",
    "        # vectorized over batch\n",
    "        grads = vmap(self._per_sample_grad)(inputs, labels)\n",
    "        influences = (grads ** 2).sum(dim=1)\n",
    "        return influences.detach().cpu()\n",
    "\n",
    "    def compute_tracin_self_influence(self, dataloader, checkpoint_paths, eta_list=None):\n",
    "        \"\"\"\n",
    "        Aggregate self-influence across checkpoints (TracInCP).\n",
    "\n",
    "        Args:\n",
    "            dataloader: DataLoader over training data.\n",
    "            checkpoint_paths: list of checkpoint file paths.\n",
    "            eta_list: optional weighting factors (default = equal).\n",
    "        Returns:\n",
    "            tensor [N] of total self-influence scores for training set.\n",
    "        \"\"\"\n",
    "        if eta_list is None:\n",
    "            eta_list = [1.0 for _ in checkpoint_paths]\n",
    "\n",
    "        # initialize empty vector for total influence\n",
    "        num_samples = len(dataloader.dataset)\n",
    "        total_influence = torch.zeros(num_samples)\n",
    "\n",
    "        for eta_i, ckpt in zip(eta_list, checkpoint_paths):\n",
    "            self.load_checkpoint(ckpt)\n",
    "\n",
    "            offset = 0\n",
    "            for inputs, labels in tqdm(dataloader, desc=f'Checkpoint {ckpt}'):\n",
    "                batch_inf = self.compute_batch_influence(inputs, labels)\n",
    "                total_influence[offset : offset + len(inputs)] += eta_i * batch_inf\n",
    "                offset += len(inputs)\n",
    "\n",
    "        return total_influence\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python hirundo_assignment",
   "language": "python",
   "name": "venv_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
